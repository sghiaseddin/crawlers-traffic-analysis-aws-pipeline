

# ========================================
# LLM BOT TRAFFIC ANALYSIS PIPELINE CONFIG
# ========================================

# ---- Project Identification ----
PROJECT_NAME="Your Project Name"
PROJECT_SLUG="your_project_name"   # used in resource naming (e.g., S3 buckets, Lambdas)

# ---- AWS Basic Configuration ----
AWS_REGION="us-east-1"             # AWS region for deployment (e.g., us-east-1)
AWS_PROFILE="default"              # AWS CLI named profile to use

# ---- S3 Buckets ----
RAW_BUCKET="${PROJECT_SLUG}-raw-logs"          # S3 bucket for unprocessed logs
PROCESSED_BUCKET="${PROJECT_SLUG}-processed"   # S3 bucket for processed logs
REPORTS_BUCKET="${PROJECT_SLUG}-reports"       # S3 bucket for reports (private)
PUBLIC_REPORTS_BUCKET="${PROJECT_SLUG}-public" # S3 bucket for public HTML reports

# ---- Lambda Configuration ----
LAMBDA_NAME="${PROJECT_SLUG}-fetch-logs"  # Lambda function name for fetching logs
LAMBDA_TIMEOUT=120                        # Lambda timeout in seconds
LAMBDA_MEMORY=512                         # Lambda memory in MB

# ---- SSH Connection (for fetching remote logs) ----
REMOTE_HOST="example.com"                                           # Hostname or IP of the remote server
REMOTE_USER="ubuntu"                                                # SSH username for the remote server
SSH_SECRET_NAME="${PROJECT_SLUG}-ssh-key"                           # AWS Secrets Manager secret for SSH key
SSH_PRIVATE_KEY_FILE="./keys/private_key.pem"                       # Path to the local SSH private key file
REMOTE_LOG_PATH="/absolute_path_to_logs/access-log-%Y-%m-%d.gz"     # Remote log file path pattern (with date placeholders)

# ---- Schedule ----
EVENTBRIDGE_SCHEDULE="cron(5 1 * * ? *)"  # Run daily at 01:05 UTC to fetch yesterday's logs

# ---- Glue (ETL) ----
GLUE_DB="${PROJECT_SLUG}_db"              # Glue database name
GLUE_CRAWLER="${PROJECT_SLUG}_crawler"    # Glue crawler name
GLUE_JOB="${PROJECT_SLUG}_etl"            # Glue ETL job name
GLUE_ROLE_NAME="Glue${PROJECT_SLUG}Role"  # IAM role for Glue jobs

# ---- Data Analyzer ----
DATA_ANALYZER_SCRIPT="analyze_bots.py"    # Script for bot analysis (placeholder)

# ---- Docker GoAccess ----
DOCKER_IMAGE_NAME="${PROJECT_SLUG}-goaccess"      # Docker image name for GoAccess
DOCKER_CONTAINER_NAME="goaccess"                  # Docker container name
PUBLIC_INDEX_KEY="site/index.html"                # S3 key for public index.html report

# ---- S3 Paths for Outputs ----
RAW_LOG_PREFIX="raw/date="                # S3 prefix for raw logs (partitioned by date)
PROCESSED_LOG_PREFIX="processed/date="    # S3 prefix for processed logs (partitioned by date)
SUMMARY_PREFIX="summaries/date="          # S3 prefix for summary outputs
CUMULATIVE_PREFIX="cumulative/"           # S3 prefix for cumulative results
BOT_MAP_KEY="config/bot_map.json"         # S3 key for bot mapping config

# ---- Benchmark / Quality Metrics ----
CRAWL_STATS_BUCKET="${PROJECT_SLUG}-crawlstats"    # S3 bucket for crawl stats
CRAWL_STATS_CSV="crawl_stats.csv"                  # Filename for Google Search Console export

# ---- General Automation ----
DEPLOY_SCRIPT="./deploy/deploy_llm_log_pipeline.sh"   # Path to deployment script
CONFIG_FILE=".env"                                    # Name of configuration file to use
